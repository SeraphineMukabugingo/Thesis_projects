{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e1980fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\" Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Preprocessing function defined successfully\n"
     ]
    }
   ],
   "source": [
    "def data_preprocessing(df, exclude_features, target_strategy='binary'):\n",
    "    \"\"\"\n",
    "    Phase 1.2: Data Preprocessing for Rwanda DHS Dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Raw dataset\n",
    "    exclude_features : list\n",
    "        Features to exclude due to data leakage\n",
    "    target_strategy : str\n",
    "        'binary' - exclude never-had-sex cases\n",
    "        'three_class' - encode as Early/Late/Never\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"PHASE 1.2: DATA PREPROCESSING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create working copy\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    print(f\"Starting dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Excluded features: {exclude_features}\")\n",
    "    print(f\"Target strategy: {target_strategy}\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # 1.2.1 HANDLE MISSING VALUES\n",
    "    # ================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"1.2.1 MISSING VALUE HANDLING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Analyze missing patterns before processing\n",
    "    missing_before = df_processed.isnull().sum()\n",
    "    missing_pct_before = (missing_before / len(df_processed)) * 100\n",
    "    \n",
    "    print(\"Missing data summary (>1% missing):\")\n",
    "    high_missing = missing_pct_before[missing_pct_before > 1].sort_values(ascending=False)\n",
    "    for var, pct in high_missing.items():\n",
    "        count = missing_before[var]\n",
    "        print(f\"  {var}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Handle target variable based on strategy\n",
    "    print(f\"\\n1.2.1.1 TARGET VARIABLE PROCESSING ({target_strategy})\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    target_before = df_processed['early_sexual_debut'].value_counts(dropna=False)\n",
    "    print(\"Target variable before processing:\")\n",
    "    for val, count in target_before.items():\n",
    "        pct = (count / len(df_processed)) * 100\n",
    "        print(f\"  {val}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    if target_strategy == 'binary':\n",
    "        # Exclude cases where early_sexual_debut is NaN (never had sex)\n",
    "        df_processed = df_processed.dropna(subset=['early_sexual_debut'])\n",
    "        print(f\"\\nAfter excluding never-had-sex cases: {df_processed.shape[0]:,} records\")\n",
    "        \n",
    "        # Convert to integer for efficiency\n",
    "        df_processed['early_sexual_debut'] = df_processed['early_sexual_debut'].astype(int)\n",
    "        \n",
    "    elif target_strategy == 'three_class':\n",
    "        # Encode NaN as 2 (Never), 1.0 as 1 (Early), 0.0 as 0 (Late)\n",
    "        df_processed['early_sexual_debut'] = df_processed['early_sexual_debut'].fillna(2)\n",
    "        df_processed['early_sexual_debut'] = df_processed['early_sexual_debut'].astype(int)\n",
    "        print(\"Three-class encoding: 0=Late debut, 1=Early debut, 2=Never had sex\")\n",
    "    \n",
    "    target_after = df_processed['early_sexual_debut'].value_counts(dropna=False)\n",
    "    print(\"Target variable after processing:\")\n",
    "    for val, count in target_after.items():\n",
    "        pct = (count / len(df_processed)) * 100\n",
    "        print(f\"  {val}: {count:,} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Remove excluded features\n",
    "    print(f\"\\n1.2.1.2 REMOVING LEAKAGE FEATURES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    features_to_remove = [f for f in exclude_features if f in df_processed.columns]\n",
    "    print(f\"Removing features: {features_to_remove}\")\n",
    "    \n",
    "    df_processed = df_processed.drop(columns=features_to_remove)\n",
    "    print(f\"Dataset shape after feature removal: {df_processed.shape}\")\n",
    "    \n",
    "    # Impute missing values for other variables\n",
    "    print(f\"\\n1.2.1.3 IMPUTATION STRATEGY\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Identify variable types for appropriate imputation\n",
    "    numeric_vars = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    numeric_vars = [var for var in numeric_vars if var != 'early_sexual_debut']\n",
    "    \n",
    "    categorical_vars = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Remove ID variables from imputation\n",
    "    id_vars = ['caseid', 'household_id', 'v001', 'v002']\n",
    "    numeric_vars = [var for var in numeric_vars if var not in id_vars]\n",
    "    categorical_vars = [var for var in categorical_vars if var not in id_vars]\n",
    "    \n",
    "    print(f\"Numeric variables for imputation: {len(numeric_vars)}\")\n",
    "    print(f\"Categorical variables for imputation: {len(categorical_vars)}\")\n",
    "    \n",
    "    # Numeric imputation - use median for robustness\n",
    "    if len(numeric_vars) > 0:\n",
    "        numeric_imputer = SimpleImputer(strategy='median')\n",
    "        df_processed[numeric_vars] = numeric_imputer.fit_transform(df_processed[numeric_vars])\n",
    "        print(\"Applied median imputation to numeric variables\")\n",
    "    \n",
    "    # Categorical imputation - use mode\n",
    "    if len(categorical_vars) > 0:\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df_processed[categorical_vars] = categorical_imputer.fit_transform(df_processed[categorical_vars])\n",
    "        print(\"Applied mode imputation to categorical variables\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # 1.2.2 FEATURE ENGINEERING\n",
    "    # ================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"1.2.2 FEATURE ENGINEERING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create binary indicators from categorical variables\n",
    "    print(\"\\n1.2.2.1 BINARY INDICATORS FROM CATEGORICAL VARIABLES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Education level (v106) - Primary/Secondary/Higher vs None\n",
    "    if 'v106' in df_processed.columns:\n",
    "        df_processed['has_education'] = (df_processed['v106'] > 0).astype(int)\n",
    "        df_processed['has_secondary_plus'] = (df_processed['v106'] >= 2).astype(int)\n",
    "        print(\"Created education indicators: has_education, has_secondary_plus\")\n",
    "    \n",
    "    # Religion (v130) - Major religions\n",
    "    if 'v130' in df_processed.columns:\n",
    "        df_processed['is_catholic'] = (df_processed['v130'] == 1).astype(int)\n",
    "        df_processed['is_protestant'] = (df_processed['v130'] == 2).astype(int)\n",
    "        df_processed['is_muslim'] = (df_processed['v130'] == 4).astype(int)\n",
    "        print(\"Created religion indicators: is_catholic, is_protestant, is_muslim\")\n",
    "    \n",
    "    # Marital status (v501) - Ever married\n",
    "    if 'v501' in df_processed.columns:\n",
    "        df_processed['ever_married'] = (df_processed['v501'] > 0).astype(int)\n",
    "        df_processed['currently_married'] = (df_processed['v501'] == 1).astype(int)\n",
    "        print(\"Created marital indicators: ever_married, currently_married\")\n",
    "    \n",
    "    # Employment (v714)\n",
    "    if 'v714' in df_processed.columns:\n",
    "        df_processed['is_employed'] = df_processed['v714'].astype(int)\n",
    "        print(\"Created employment indicator: is_employed\")\n",
    "    \n",
    "    # Household assets\n",
    "    asset_vars = ['hv206', 'hv207', 'hv208']  # electricity, radio, TV\n",
    "    asset_names = ['has_electricity', 'has_radio', 'has_tv']\n",
    "    \n",
    "    for asset_var, asset_name in zip(asset_vars, asset_names):\n",
    "        if asset_var in df_processed.columns:\n",
    "            df_processed[asset_name] = df_processed[asset_var].astype(int)\n",
    "    \n",
    "    # Asset count\n",
    "    if all(var in df_processed.columns for var in asset_names):\n",
    "        df_processed['total_assets'] = df_processed[asset_names].sum(axis=1)\n",
    "        print(\"Created asset indicators and total_assets count\")\n",
    "    \n",
    "    # Scale continuous variables\n",
    "    print(\"\\n1.2.2.2 SCALING CONTINUOUS VARIABLES\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    continuous_to_scale = ['v107', 'v191', 'hv271']  # education years, wealth scores\n",
    "    continuous_present = [var for var in continuous_to_scale if var in df_processed.columns]\n",
    "    \n",
    "    if len(continuous_present) > 0:\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        # Create scaled versions\n",
    "        scaled_names = [f\"{var}_scaled\" for var in continuous_present]\n",
    "        df_processed[scaled_names] = scaler.fit_transform(df_processed[continuous_present])\n",
    "        \n",
    "        print(f\"Scaled variables: {continuous_present}\")\n",
    "        print(f\"New scaled variables: {scaled_names}\")\n",
    "        \n",
    "        # Store scaler for later use\n",
    "        scaling_info = {\n",
    "            'scaler': scaler,\n",
    "            'original_vars': continuous_present,\n",
    "            'scaled_vars': scaled_names\n",
    "        }\n",
    "    else:\n",
    "        scaling_info = None\n",
    "    \n",
    "    # Generate interaction terms for key predictors\n",
    "    print(\"\\n1.2.2.3 INTERACTION TERMS\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    interactions_created = []\n",
    "    \n",
    "    # Age Ã— Education interaction\n",
    "    if 'v012' in df_processed.columns and 'v107' in df_processed.columns:\n",
    "        df_processed['age_education_interaction'] = df_processed['v012'] * df_processed['v107']\n",
    "        interactions_created.append('age_education_interaction')\n",
    "    \n",
    "    # Age Ã— Wealth interaction  \n",
    "    if 'v012' in df_processed.columns and 'v191' in df_processed.columns:\n",
    "        df_processed['age_wealth_interaction'] = df_processed['v012'] * df_processed['v191']\n",
    "        interactions_created.append('age_wealth_interaction')\n",
    "    \n",
    "    # Education Ã— Wealth interaction\n",
    "    if 'v107' in df_processed.columns and 'v191' in df_processed.columns:\n",
    "        df_processed['education_wealth_interaction'] = df_processed['v107'] * df_processed['v191']\n",
    "        interactions_created.append('education_wealth_interaction')\n",
    "    \n",
    "    # Urban Ã— Education interaction\n",
    "    if 'v102' in df_processed.columns and 'v107' in df_processed.columns:\n",
    "        df_processed['urban_education_interaction'] = df_processed['v102'] * df_processed['v107']\n",
    "        interactions_created.append('urban_education_interaction')\n",
    "    \n",
    "    print(f\"Created interaction terms: {interactions_created}\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # 1.2.3 GEOGRAPHIC STRATIFICATION\n",
    "    # ================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"1.2.3 GEOGRAPHIC STRATIFICATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create region indicators\n",
    "    if 'v101' in df_processed.columns:\n",
    "        print(\"\\n1.2.3.1 REGIONAL INDICATORS\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        region_names = {1: 'kigali', 2: 'south', 3: 'west', 4: 'north', 5: 'east'}\n",
    "        \n",
    "        for region_code, region_name in region_names.items():\n",
    "            col_name = f'region_{region_name}'\n",
    "            df_processed[col_name] = (df_processed['v101'] == region_code).astype(int)\n",
    "        \n",
    "        region_distribution = df_processed['v101'].value_counts().sort_index()\n",
    "        print(\"Regional distribution:\")\n",
    "        for region_code, count in region_distribution.items():\n",
    "            region_name = region_names.get(region_code, f'Unknown_{region_code}')\n",
    "            pct = (count / len(df_processed)) * 100\n",
    "            print(f\"  {region_name.title()}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        print(f\"Created regional dummy variables: {list(region_names.values())}\")\n",
    "    \n",
    "    # Urban/rural stratification\n",
    "    if 'v102' in df_processed.columns:\n",
    "        print(\"\\n1.2.3.2 URBAN/RURAL STRATIFICATION\")\n",
    "        print(\"-\" * 35)\n",
    "        \n",
    "        df_processed['is_urban'] = (df_processed['v102'] == 1).astype(int)\n",
    "        df_processed['is_rural'] = (df_processed['v102'] == 2).astype(int)\n",
    "        \n",
    "        urban_rural_dist = df_processed['v102'].value_counts()\n",
    "        print(\"Urban/Rural distribution:\")\n",
    "        print(f\"  Urban: {urban_rural_dist.get(1, 0):,} ({urban_rural_dist.get(1, 0)/len(df_processed)*100:.1f}%)\")\n",
    "        print(f\"  Rural: {urban_rural_dist.get(2, 0):,} ({urban_rural_dist.get(2, 0)/len(df_processed)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"Created urban/rural indicators: is_urban, is_rural\")\n",
    "    \n",
    "    # ================================================================\n",
    "    # 1.2.4 FINAL PREPROCESSING SUMMARY\n",
    "    # ================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"1.2.4 PREPROCESSING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Data shape summary\n",
    "    print(f\"Final dataset shape: {df_processed.shape}\")\n",
    "    print(f\"Records processed: {df_processed.shape[0]:,}\")\n",
    "    print(f\"Features available: {df_processed.shape[1]:,}\")\n",
    "    \n",
    "    # Feature categories\n",
    "    feature_summary = {\n",
    "        'target': ['early_sexual_debut'],\n",
    "        'demographics': ['v012', 'v013'],\n",
    "        'geographic': ['v101', 'v102'] + [col for col in df_processed.columns if col.startswith('region_') or col.startswith('is_urban') or col.startswith('is_rural')],\n",
    "        'education': ['v106', 'v107', 'v149', 'v150', 'v151', 'v152'] + [col for col in df_processed.columns if 'education' in col],\n",
    "        'socioeconomic': ['v130', 'v190', 'v191', 'hv270', 'hv271'] + [col for col in df_processed.columns if any(x in col for x in ['wealth', 'religion', 'catholic', 'protestant', 'muslim'])],\n",
    "        'household': ['hv009'] + [col for col in df_processed.columns if any(x in col for x in ['asset', 'electricity', 'radio', 'tv'])],\n",
    "        'marital': ['v501', 'v502'] + [col for col in df_processed.columns if 'married' in col],\n",
    "        'fertility': ['v201', 'v213', 'bord', 'b5'],\n",
    "        'family_planning': ['v301', 'v312', 'v602'],\n",
    "        'health': ['v157', 'v158', 'v384a', 'v384b'],\n",
    "        'employment': ['v714'] + [col for col in df_processed.columns if 'employed' in col],\n",
    "        'interactions': interactions_created,\n",
    "        'scaled': scaled_names if scaling_info else []\n",
    "    }\n",
    "    \n",
    "    print(\"\\nFeature categories:\")\n",
    "    total_features = 0\n",
    "    for category, features in feature_summary.items():\n",
    "        available_features = [f for f in features if f in df_processed.columns]\n",
    "        if available_features:\n",
    "            print(f\"  {category.title()}: {len(available_features)} features\")\n",
    "            total_features += len(available_features)\n",
    "    \n",
    "    print(f\"\\nTotal categorized features: {total_features}\")\n",
    "    \n",
    "    # Missing data after preprocessing\n",
    "    missing_after = df_processed.isnull().sum().sum()\n",
    "    print(f\"Missing values after preprocessing: {missing_after:,}\")\n",
    "    \n",
    "    if missing_after == 0:\n",
    "        print(\"âœ“ All missing values handled successfully\")\n",
    "    else:\n",
    "        print(f\"  {missing_after} missing values remain\")\n",
    "    \n",
    "    # Data types summary\n",
    "    print(f\"\\nData types summary:\")\n",
    "    dtype_counts = df_processed.dtypes.value_counts()\n",
    "    for dtype, count in dtype_counts.items():\n",
    "        print(f\"  {dtype}: {count} variables\")\n",
    "    \n",
    "    # Memory usage\n",
    "    memory_mb = df_processed.memory_usage(deep=True).sum() / 1024**2\n",
    "    print(f\"\\nMemory usage: {memory_mb:.1f} MB\")\n",
    "    \n",
    "    return df_processed, {\n",
    "        'scaling_info': scaling_info,\n",
    "        'feature_summary': feature_summary,\n",
    "        'target_strategy': target_strategy,\n",
    "        'interactions_created': interactions_created,\n",
    "        'preprocessing_stats': {\n",
    "            'original_shape': df.shape,\n",
    "            'final_shape': df_processed.shape,\n",
    "            'missing_before': missing_before.sum(),\n",
    "            'missing_after': missing_after,\n",
    "            'memory_mb': memory_mb\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Preprocessing function defined successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003905b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset loaded successfully\n",
      "  Shape: (14634, 44)\n",
      "  Records: 14,634\n",
      "  Features: 44\n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14634 entries, 0 to 14633\n",
      "Data columns (total 44 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   v525                14634 non-null  int64  \n",
      " 1   early_sexual_debut  14634 non-null  float64\n",
      " 2   v012                14634 non-null  int64  \n",
      " 3   v013                14634 non-null  int64  \n",
      " 4   v101                14634 non-null  int64  \n",
      " 5   v102                14634 non-null  int64  \n",
      " 6   v106                14634 non-null  int64  \n",
      " 7   v107                13282 non-null  float64\n",
      " 8   v130                14634 non-null  int64  \n",
      " 9   v190                14634 non-null  int64  \n",
      " 10  v191                14634 non-null  int64  \n",
      " 11  hv270               14634 non-null  int64  \n",
      " 12  hv271               14634 non-null  int64  \n",
      " 13  v149                14634 non-null  int64  \n",
      " 14  v150                14634 non-null  int64  \n",
      " 15  v151                14634 non-null  int64  \n",
      " 16  v152                14634 non-null  int64  \n",
      " 17  hv009               14634 non-null  int64  \n",
      " 18  hv025               14634 non-null  int64  \n",
      " 19  hv024               14634 non-null  int64  \n",
      " 20  v501                14634 non-null  int64  \n",
      " 21  v502                14634 non-null  int64  \n",
      " 22  v511                8574 non-null   float64\n",
      " 23  v512                8574 non-null   float64\n",
      " 24  v201                14634 non-null  int64  \n",
      " 25  v212                9214 non-null   float64\n",
      " 26  v213                14634 non-null  int64  \n",
      " 27  bord                14634 non-null  float64\n",
      " 28  b5                  14634 non-null  float64\n",
      " 29  v301                14634 non-null  int64  \n",
      " 30  v312                14634 non-null  int64  \n",
      " 31  v602                14634 non-null  int64  \n",
      " 32  v714                14634 non-null  int64  \n",
      " 33  v157                14634 non-null  int64  \n",
      " 34  v158                14634 non-null  int64  \n",
      " 35  v384a               14634 non-null  int64  \n",
      " 36  v384b               14634 non-null  int64  \n",
      " 37  hv206               14634 non-null  int64  \n",
      " 38  hv207               14634 non-null  int64  \n",
      " 39  hv208               14634 non-null  int64  \n",
      " 40  caseid              14634 non-null  object \n",
      " 41  v001                14634 non-null  int64  \n",
      " 42  v002                14634 non-null  int64  \n",
      " 43  household_id        14634 non-null  object \n",
      "dtypes: float64(7), int64(35), object(2)\n",
      "memory usage: 4.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(dataset_path)\n",
    "    print(\"âœ“ Dataset loaded successfully\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Records: {df.shape[0]:,}\")\n",
    "    print(f\"  Features: {df.shape[1]:,}\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nDataset info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\" Dataset not found. Please check the file path.\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading dataset: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd3833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of raw data:\n",
      "   v525  early_sexual_debut  v012  v013  v101  v102  v106  v107  v130  v190  \\\n",
      "0     0                 1.0    24     2     1     2     3   3.0     1     4   \n",
      "1    17                 1.0    42     6     1     2     1   4.0     2     3   \n",
      "2    22                 0.0    32     4     1     2     2   6.0     1     5   \n",
      "3     0                 1.0    29     3     1     2     2   6.0     2     3   \n",
      "4    19                 0.0    36     5     1     2     2   0.0     1     4   \n",
      "\n",
      "   ...  v158  v384a  v384b  hv206  hv207  hv208           caseid  v001  v002  \\\n",
      "0  ...     0      0      0      1      0      0         1   3 02     1     3   \n",
      "1  ...     0      0      0      1      0      0         1   4 01     1     4   \n",
      "2  ...     2      1      1      1      1      1         1   5 02     1     5   \n",
      "3  ...     2      0      0      1      1      0         1   6 03     1     6   \n",
      "4  ...     2      1      0      1      0      0         1   7 02     1     7   \n",
      "\n",
      "   household_id  \n",
      "0           1_3  \n",
      "1           1_4  \n",
      "2           1_5  \n",
      "3           1_6  \n",
      "4           1_7  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "\n",
      "Target variable distribution:\n",
      "early_sexual_debut\n",
      "0.0    7919\n",
      "1.0    6715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"First few rows of raw data:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['early_sexual_debut'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4982c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PHASE 1.2: DATA PREPROCESSING\n",
      "================================================================================\n",
      "Starting dataset shape: (14634, 44)\n",
      "Excluded features: ['v525', 'v512', 'v511', 'v212']\n",
      "Target strategy: binary\n",
      "\n",
      "============================================================\n",
      "1.2.1 MISSING VALUE HANDLING\n",
      "============================================================\n",
      "Missing data summary (>1% missing):\n",
      "  v511: 6,060 (41.4%)\n",
      "  v512: 6,060 (41.4%)\n",
      "  v212: 5,420 (37.0%)\n",
      "  v107: 1,352 (9.2%)\n",
      "\n",
      "1.2.1.1 TARGET VARIABLE PROCESSING (binary)\n",
      "----------------------------------------\n",
      "Target variable before processing:\n",
      "  0.0: 7,919 (54.1%)\n",
      "  1.0: 6,715 (45.9%)\n",
      "\n",
      "After excluding never-had-sex cases: 14,634 records\n",
      "Target variable after processing:\n",
      "  0: 7,919 (54.1%)\n",
      "  1: 6,715 (45.9%)\n",
      "\n",
      "1.2.1.2 REMOVING LEAKAGE FEATURES\n",
      "----------------------------------------\n",
      "Removing features: ['v525', 'v512', 'v511', 'v212']\n",
      "Dataset shape after feature removal: (14634, 40)\n",
      "\n",
      "1.2.1.3 IMPUTATION STRATEGY\n",
      "----------------------------------------\n",
      "Numeric variables for imputation: 35\n",
      "Categorical variables for imputation: 0\n",
      "Applied median imputation to numeric variables\n",
      "\n",
      "============================================================\n",
      "1.2.2 FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "1.2.2.1 BINARY INDICATORS FROM CATEGORICAL VARIABLES\n",
      "--------------------------------------------------\n",
      "Created education indicators: has_education, has_secondary_plus\n",
      "Created religion indicators: is_catholic, is_protestant, is_muslim\n",
      "Created marital indicators: ever_married, currently_married\n",
      "Created employment indicator: is_employed\n",
      "Created asset indicators and total_assets count\n",
      "\n",
      "1.2.2.2 SCALING CONTINUOUS VARIABLES\n",
      "----------------------------------------\n",
      "Scaled variables: ['v107', 'v191', 'hv271']\n",
      "New scaled variables: ['v107_scaled', 'v191_scaled', 'hv271_scaled']\n",
      "\n",
      "1.2.2.3 INTERACTION TERMS\n",
      "------------------------------\n",
      "Created interaction terms: ['age_education_interaction', 'age_wealth_interaction', 'education_wealth_interaction', 'urban_education_interaction']\n",
      "\n",
      "============================================================\n",
      "1.2.3 GEOGRAPHIC STRATIFICATION\n",
      "============================================================\n",
      "\n",
      "1.2.3.1 REGIONAL INDICATORS\n",
      "------------------------------\n",
      "Regional distribution:\n",
      "  Kigali: 1,921 (13.1%)\n",
      "  South: 3,482 (23.8%)\n",
      "  West: 3,312 (22.6%)\n",
      "  North: 2,294 (15.7%)\n",
      "  East: 3,625 (24.8%)\n",
      "Created regional dummy variables: ['kigali', 'south', 'west', 'north', 'east']\n",
      "\n",
      "1.2.3.2 URBAN/RURAL STRATIFICATION\n",
      "-----------------------------------\n",
      "Urban/Rural distribution:\n",
      "  Urban: 3,551 (24.3%)\n",
      "  Rural: 11,083 (75.7%)\n",
      "Created urban/rural indicators: is_urban, is_rural\n",
      "\n",
      "============================================================\n",
      "1.2.4 PREPROCESSING SUMMARY\n",
      "============================================================\n",
      "Final dataset shape: (14634, 66)\n",
      "Records processed: 14,634\n",
      "Features available: 66\n",
      "\n",
      "Feature categories:\n",
      "  Target: 1 features\n",
      "  Demographics: 2 features\n",
      "  Geographic: 9 features\n",
      "  Education: 10 features\n",
      "  Socioeconomic: 10 features\n",
      "  Household: 5 features\n",
      "  Marital: 4 features\n",
      "  Fertility: 4 features\n",
      "  Family_Planning: 3 features\n",
      "  Health: 4 features\n",
      "  Employment: 2 features\n",
      "  Interactions: 4 features\n",
      "  Scaled: 3 features\n",
      "\n",
      "Total categorized features: 61\n",
      "Missing values after preprocessing: 0\n",
      "âœ“ All missing values handled successfully\n",
      "\n",
      "Data types summary:\n",
      "  float64: 42 variables\n",
      "  int64: 22 variables\n",
      "  object: 2 variables\n",
      "\n",
      "Memory usage: 8.8 MB\n",
      "\n",
      "================================================================================\n",
      "PREPROCESSING COMPLETE\n",
      "================================================================================\n",
      "âœ“ Ready for modeling with 14,634 samples and 66 features\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_processed, preprocessing_info = data_preprocessing(\n",
    "        df, \n",
    "        exclude_features, \n",
    "        target_strategy=target_strategy\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PREPROCESSING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ“ Ready for modeling with {df_processed.shape[0]:,} samples and {df_processed.shape[1]:,} features\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error during preprocessing: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2b4b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of processed data:\n",
      "   early_sexual_debut  v012  v013  v101  v102  v106  v107  v130  v190  \\\n",
      "0                   1  24.0   2.0   1.0   2.0   3.0   3.0   1.0   4.0   \n",
      "1                   1  42.0   6.0   1.0   2.0   1.0   4.0   2.0   3.0   \n",
      "2                   0  32.0   4.0   1.0   2.0   2.0   6.0   1.0   5.0   \n",
      "3                   1  29.0   3.0   1.0   2.0   2.0   6.0   2.0   3.0   \n",
      "4                   0  36.0   5.0   1.0   2.0   2.0   0.0   1.0   4.0   \n",
      "5                   1  23.0   2.0   1.0   2.0   2.0   6.0   2.0   5.0   \n",
      "6                   0  38.0   5.0   1.0   2.0   2.0   6.0   1.0   5.0   \n",
      "7                   0  30.0   4.0   1.0   2.0   2.0   6.0   3.0   3.0   \n",
      "8                   1  46.0   7.0   1.0   2.0   1.0   3.0   1.0   2.0   \n",
      "9                   0  41.0   6.0   1.0   2.0   1.0   4.0   2.0   5.0   \n",
      "\n",
      "       v191  ...  age_wealth_interaction  education_wealth_interaction  \\\n",
      "0   61640.0  ...               1479360.0                      184920.0   \n",
      "1  -44072.0  ...              -1851024.0                     -176288.0   \n",
      "2  191074.0  ...               6114368.0                     1146444.0   \n",
      "3  -14202.0  ...               -411858.0                      -85212.0   \n",
      "4    1461.0  ...                 52596.0                           0.0   \n",
      "5   93246.0  ...               2144658.0                      559476.0   \n",
      "6  127487.0  ...               4844506.0                      764922.0   \n",
      "7  -25490.0  ...               -764700.0                     -152940.0   \n",
      "8  -65402.0  ...              -3008492.0                     -196206.0   \n",
      "9  122316.0  ...               5014956.0                      489264.0   \n",
      "\n",
      "   urban_education_interaction  region_kigali  region_south  region_west  \\\n",
      "0                          6.0              1             0            0   \n",
      "1                          8.0              1             0            0   \n",
      "2                         12.0              1             0            0   \n",
      "3                         12.0              1             0            0   \n",
      "4                          0.0              1             0            0   \n",
      "5                         12.0              1             0            0   \n",
      "6                         12.0              1             0            0   \n",
      "7                         12.0              1             0            0   \n",
      "8                          6.0              1             0            0   \n",
      "9                          8.0              1             0            0   \n",
      "\n",
      "   region_north  region_east  is_urban  is_rural  \n",
      "0             0            0         0         1  \n",
      "1             0            0         0         1  \n",
      "2             0            0         0         1  \n",
      "3             0            0         0         1  \n",
      "4             0            0         0         1  \n",
      "5             0            0         0         1  \n",
      "6             0            0         0         1  \n",
      "7             0            0         0         1  \n",
      "8             0            0         0         1  \n",
      "9             0            0         0         1  \n",
      "\n",
      "[10 rows x 66 columns]\n",
      "\n",
      "Processed data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14634 entries, 0 to 14633\n",
      "Data columns (total 66 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   early_sexual_debut            14634 non-null  int64  \n",
      " 1   v012                          14634 non-null  float64\n",
      " 2   v013                          14634 non-null  float64\n",
      " 3   v101                          14634 non-null  float64\n",
      " 4   v102                          14634 non-null  float64\n",
      " 5   v106                          14634 non-null  float64\n",
      " 6   v107                          14634 non-null  float64\n",
      " 7   v130                          14634 non-null  float64\n",
      " 8   v190                          14634 non-null  float64\n",
      " 9   v191                          14634 non-null  float64\n",
      " 10  hv270                         14634 non-null  float64\n",
      " 11  hv271                         14634 non-null  float64\n",
      " 12  v149                          14634 non-null  float64\n",
      " 13  v150                          14634 non-null  float64\n",
      " 14  v151                          14634 non-null  float64\n",
      " 15  v152                          14634 non-null  float64\n",
      " 16  hv009                         14634 non-null  float64\n",
      " 17  hv025                         14634 non-null  float64\n",
      " 18  hv024                         14634 non-null  float64\n",
      " 19  v501                          14634 non-null  float64\n",
      " 20  v502                          14634 non-null  float64\n",
      " 21  v201                          14634 non-null  float64\n",
      " 22  v213                          14634 non-null  float64\n",
      " 23  bord                          14634 non-null  float64\n",
      " 24  b5                            14634 non-null  float64\n",
      " 25  v301                          14634 non-null  float64\n",
      " 26  v312                          14634 non-null  float64\n",
      " 27  v602                          14634 non-null  float64\n",
      " 28  v714                          14634 non-null  float64\n",
      " 29  v157                          14634 non-null  float64\n",
      " 30  v158                          14634 non-null  float64\n",
      " 31  v384a                         14634 non-null  float64\n",
      " 32  v384b                         14634 non-null  float64\n",
      " 33  hv206                         14634 non-null  float64\n",
      " 34  hv207                         14634 non-null  float64\n",
      " 35  hv208                         14634 non-null  float64\n",
      " 36  caseid                        14634 non-null  object \n",
      " 37  v001                          14634 non-null  int64  \n",
      " 38  v002                          14634 non-null  int64  \n",
      " 39  household_id                  14634 non-null  object \n",
      " 40  has_education                 14634 non-null  int64  \n",
      " 41  has_secondary_plus            14634 non-null  int64  \n",
      " 42  is_catholic                   14634 non-null  int64  \n",
      " 43  is_protestant                 14634 non-null  int64  \n",
      " 44  is_muslim                     14634 non-null  int64  \n",
      " 45  ever_married                  14634 non-null  int64  \n",
      " 46  currently_married             14634 non-null  int64  \n",
      " 47  is_employed                   14634 non-null  int64  \n",
      " 48  has_electricity               14634 non-null  int64  \n",
      " 49  has_radio                     14634 non-null  int64  \n",
      " 50  has_tv                        14634 non-null  int64  \n",
      " 51  total_assets                  14634 non-null  int64  \n",
      " 52  v107_scaled                   14634 non-null  float64\n",
      " 53  v191_scaled                   14634 non-null  float64\n",
      " 54  hv271_scaled                  14634 non-null  float64\n",
      " 55  age_education_interaction     14634 non-null  float64\n",
      " 56  age_wealth_interaction        14634 non-null  float64\n",
      " 57  education_wealth_interaction  14634 non-null  float64\n",
      " 58  urban_education_interaction   14634 non-null  float64\n",
      " 59  region_kigali                 14634 non-null  int64  \n",
      " 60  region_south                  14634 non-null  int64  \n",
      " 61  region_west                   14634 non-null  int64  \n",
      " 62  region_north                  14634 non-null  int64  \n",
      " 63  region_east                   14634 non-null  int64  \n",
      " 64  is_urban                      14634 non-null  int64  \n",
      " 65  is_rural                      14634 non-null  int64  \n",
      "dtypes: float64(42), int64(22), object(2)\n",
      "memory usage: 7.4+ MB\n",
      "None\n",
      "\n",
      "Target variable distribution after preprocessing:\n",
      "early_sexual_debut\n",
      "0    7919\n",
      "1    6715\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of processed data:\")\n",
    "print(df_processed.head(10))\n",
    "\n",
    "print(\"\\nProcessed data info:\")\n",
    "print(df_processed.info())\n",
    "\n",
    "print(\"\\nTarget variable distribution after preprocessing:\")\n",
    "print(df_processed['early_sexual_debut'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49cba5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPROCESSING STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Original shape: (14634, 44)\n",
      "Final shape: (14634, 66)\n",
      "Records removed: 0\n",
      "Features removed: -22\n",
      "Missing values before: 18,892\n",
      "Missing values after: 0\n",
      "Memory usage: 8.80 MB\n",
      "\n",
      "Interactions created:\n",
      "  - age_education_interaction\n",
      "  - age_wealth_interaction\n",
      "  - education_wealth_interaction\n",
      "  - urban_education_interaction\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PREPROCESSING STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats = preprocessing_info['preprocessing_stats']\n",
    "print(f\"\\nOriginal shape: {stats['original_shape']}\")\n",
    "print(f\"Final shape: {stats['final_shape']}\")\n",
    "print(f\"Records removed: {stats['original_shape'][0] - stats['final_shape'][0]:,}\")\n",
    "print(f\"Features removed: {stats['original_shape'][1] - stats['final_shape'][1]}\")\n",
    "print(f\"Missing values before: {stats['missing_before']:,}\")\n",
    "print(f\"Missing values after: {stats['missing_after']:,}\")\n",
    "print(f\"Memory usage: {stats['memory_mb']:.2f} MB\")\n",
    "\n",
    "print(f\"\\nInteractions created:\")\n",
    "for interaction in preprocessing_info['interactions_created']:\n",
    "    print(f\"  - {interaction}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2601f5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE CATEGORIES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "TARGET (1 features):\n",
      "  - early_sexual_debut\n",
      "\n",
      "DEMOGRAPHICS (2 features):\n",
      "  - v012\n",
      "  - v013\n",
      "\n",
      "GEOGRAPHIC (9 features):\n",
      "  - v101\n",
      "  - v102\n",
      "  - region_kigali\n",
      "  - region_south\n",
      "  - region_west\n",
      "  - region_north\n",
      "  - region_east\n",
      "  - is_urban\n",
      "  - is_rural\n",
      "\n",
      "EDUCATION (10 features):\n",
      "  - v106\n",
      "  - v107\n",
      "  - v149\n",
      "  - v150\n",
      "  - v151\n",
      "  - v152\n",
      "  - has_education\n",
      "  - age_education_interaction\n",
      "  - education_wealth_interaction\n",
      "  - urban_education_interaction\n",
      "\n",
      "SOCIOECONOMIC (10 features):\n",
      "  - v130\n",
      "  - v190\n",
      "  - v191\n",
      "  - hv270\n",
      "  - hv271\n",
      "  - is_catholic\n",
      "  - is_protestant\n",
      "  - is_muslim\n",
      "  - age_wealth_interaction\n",
      "  - education_wealth_interaction\n",
      "\n",
      "HOUSEHOLD (5 features):\n",
      "  - hv009\n",
      "  - has_electricity\n",
      "  - has_radio\n",
      "  - has_tv\n",
      "  - total_assets\n",
      "\n",
      "MARITAL (4 features):\n",
      "  - v501\n",
      "  - v502\n",
      "  - ever_married\n",
      "  - currently_married\n",
      "\n",
      "FERTILITY (4 features):\n",
      "  - v201\n",
      "  - v213\n",
      "  - bord\n",
      "  - b5\n",
      "\n",
      "FAMILY_PLANNING (3 features):\n",
      "  - v301\n",
      "  - v312\n",
      "  - v602\n",
      "\n",
      "HEALTH (4 features):\n",
      "  - v157\n",
      "  - v158\n",
      "  - v384a\n",
      "  - v384b\n",
      "\n",
      "EMPLOYMENT (2 features):\n",
      "  - v714\n",
      "  - is_employed\n",
      "\n",
      "INTERACTIONS (4 features):\n",
      "  - age_education_interaction\n",
      "  - age_wealth_interaction\n",
      "  - education_wealth_interaction\n",
      "  - urban_education_interaction\n",
      "\n",
      "SCALED (3 features):\n",
      "  - v107_scaled\n",
      "  - v191_scaled\n",
      "  - hv271_scaled\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE CATEGORIES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "feature_summary = preprocessing_info['feature_summary']\n",
    "\n",
    "for category, features in feature_summary.items():\n",
    "    available_features = [f for f in features if f in df_processed.columns]\n",
    "    if available_features:\n",
    "        print(f\"\\n{category.upper()} ({len(available_features)} features):\")\n",
    "        for feature in available_features[:10]:  # Show first 10\n",
    "            print(f\"  - {feature}\")\n",
    "        if len(available_features) > 10:\n",
    "            print(f\"  ... and {len(available_features) - 10} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb9cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ No missing values in processed dataset\n"
     ]
    }
   ],
   "source": [
    "missing_check = df_processed.isnull().sum()\n",
    "missing_vars = missing_check[missing_check > 0]\n",
    "\n",
    "if len(missing_vars) == 0:\n",
    "    print(\"âœ“ No missing values in processed dataset\")\n",
    "else:\n",
    "    print(\" Missing values found:\")\n",
    "    for var, count in missing_vars.items():\n",
    "        pct = (count / len(df_processed)) * 100\n",
    "        print(f\"  {var}: {count:,} ({pct:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b10a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Processed data saved successfully\n",
      "  Location: C:/Users/USER/Desktop/seraphine_thesis/findatasets/rwanda_dhs_processed.csv\n",
      "  Size: 14,634 rows Ã— 66 columns\n"
     ]
    }
   ],
   "source": [
    "output_path = r\"C:/Users/USER/Desktop/seraphine_thesis/findatasets/rwanda_dhs_processed.csv\"\n",
    "\n",
    "try:\n",
    "    df_processed.to_csv(output_path, index=False)\n",
    "    print(f\"âœ“ Processed data saved successfully\")\n",
    "    print(f\"  Location: {output_path}\")\n",
    "    print(f\"  Size: {df_processed.shape[0]:,} rows Ã— {df_processed.shape[1]:,} columns\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" Error saving processed data: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c3513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FINAL SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š DATASET OVERVIEW\n",
      "  Original records: 14,634\n",
      "  Processed records: 14,634\n",
      "  Records retained: 100.0%\n",
      "  Original features: 44\n",
      "  Final features: 66\n",
      "\n",
      "ðŸŽ¯ TARGET VARIABLE\n",
      "  Late Debut (0): 7,919 (54.1%)\n",
      "  Early Debut (1): 6,715 (45.9%)\n",
      "\n",
      "âœ¨ FEATURE ENGINEERING\n",
      "  Interaction terms created: 4\n",
      "  Variables scaled: 3\n",
      "  Binary indicators created: Multiple\n",
      "\n",
      "ðŸ’¾ OUTPUT\n",
      "  File saved: C:/Users/USER/Desktop/seraphine_thesis/findatasets/rwanda_dhs_processed.csv\n",
      "  Memory usage: 8.80 MB\n",
      "\n",
      "================================================================================\n",
      "âœ“ PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n DATASET OVERVIEW\")\n",
    "print(f\"  Original records: {df.shape[0]:,}\")\n",
    "print(f\"  Processed records: {df_processed.shape[0]:,}\")\n",
    "print(f\"  Records retained: {df_processed.shape[0]/df.shape[0]*100:.1f}%\")\n",
    "print(f\"  Original features: {df.shape[1]:,}\")\n",
    "print(f\"  Final features: {df_processed.shape[1]:,}\")\n",
    "\n",
    "print(\"\\n TARGET VARIABLE\")\n",
    "target_dist = df_processed['early_sexual_debut'].value_counts()\n",
    "for value, count in target_dist.items():\n",
    "    pct = (count / len(df_processed)) * 100\n",
    "    label = \"Early Debut\" if value == 1 else \"Late Debut\"\n",
    "    print(f\"  {label} ({value}): {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n FEATURE ENGINEERING\")\n",
    "print(f\"  Interaction terms created: {len(preprocessing_info['interactions_created'])}\")\n",
    "if preprocessing_info['scaling_info']:\n",
    "    print(f\"  Variables scaled: {len(preprocessing_info['scaling_info']['original_vars'])}\")\n",
    "print(f\"  Binary indicators created: Multiple\")\n",
    "\n",
    "print(\"\\n OUTPUT\")\n",
    "print(f\"  File saved: {output_path}\")\n",
    "print(f\"  Memory usage: {stats['memory_mb']:.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ“ PREPROCESSING PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad428a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
